# YOLOv26 Research Variant Configuration

model:
  name: "YOLOv26"
  version: "1.0.0"
  
  # Backbone Architecture
  backbone:
    type: "CSPDarknet"
    depth_multiple: 1.0
    width_multiple: 1.0
    activation: "SiLU"
  
  # Neck Architecture
  neck:
    type: "PAN-FPN"
    in_channels: [256, 512, 1024]
    out_channels: [256, 512, 1024]
  
  # Multi-Head Detection
  heads:
    detection:
      enabled: true
      num_classes: 80  # COCO classes
      anchors: 3
      stride: [8, 16, 32]
    
    crowd_density:
      enabled: true
      output_dim: 1
      activation: "sigmoid"
    
    behavior_embedding:
      enabled: true
      embedding_dim: 512
      normalize: true
    
    pose_fusion:
      enabled: true
      pose_dim: 17  # MediaPipe keypoints
      fusion_method: "concat"  # or "attention"

# Training Configuration
training:
  batch_size: 16
  epochs: 300
  learning_rate: 0.01
  momentum: 0.937
  weight_decay: 0.0005
  warmup_epochs: 3
  warmup_momentum: 0.8
  warmup_bias_lr: 0.1
  
  optimizer: "SGD"
  scheduler: "cosine"
  
  augmentation:
    mosaic: 1.0
    mixup: 0.1
    hsv_h: 0.015
    hsv_s: 0.7
    hsv_v: 0.4
    degrees: 10.0
    translate: 0.1
    scale: 0.5
    shear: 2.0
    perspective: 0.0
    flipud: 0.0
    fliplr: 0.5
    rotate: 0.0

# Validation Configuration
validation:
  val_split: 0.1
  metrics:
    - "mAP@0.5"
    - "mAP@0.5:0.95"
    - "crowd_density_mae"
    - "behavior_embedding_cosine"

# Inference Configuration
inference:
  img_size: 640
  conf_threshold: 0.5
  iou_threshold: 0.45
  max_detections: 1000
  device: "cuda:0"
  
  temporal:
    buffer_size: 30
    enable_temporal_smoothing: true
    temporal_alpha: 0.7
